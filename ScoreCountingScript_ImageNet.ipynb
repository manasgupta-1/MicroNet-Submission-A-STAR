{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating score for Micronet Challange"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remark: We don't have to account for Batch Norm parameters and FLOPS - https://tehnokv.com/posts/fusing-batchnorm-and-conv/ since they can be fused with the preceding convolutional layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`counting.py` script is taken from https://github.com/google-research/google-research/blob/master/micronet_challenge/counting.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "import numpy as np\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "from counting import Conv2D, FullyConnected, GlobalAvg, Add, DepthWiseConv2D, Scale, count_ops, get_conv_output_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ImageNet submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at MobileNetV2 architecture which is a baseline architecture for calculating the score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_model = models.__dict__['mobilenet_v2'](width_mult=1.4)\n",
    "# print(baseline_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get all the operations in the MobileNetV2 architecture - as stated earlier in the remark we can ignore BatchNorm layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_image_size = 224\n",
    "#kernel_shape = k_size, _, c_in, c_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_mobilenet_conv_op(module, input_size):\n",
    "    padding = 'same' if module.padding==(1,1) else 'valid'\n",
    "    if module.groups == module.in_channels:\n",
    "        op_type = DepthWiseConv2D\n",
    "        kernel_shape=module.kernel_size + (module.in_channels, 1)\n",
    "    else:\n",
    "        op_type = Conv2D\n",
    "        kernel_shape=module.kernel_size + (module.in_channels, module.out_channels)\n",
    "    return op_type(input_size=input_size, \n",
    "                kernel_shape=kernel_shape, \n",
    "                strides=module.stride,\n",
    "                padding=padding,\n",
    "                use_bias=False,\n",
    "                activation='relu')\n",
    "\n",
    "\n",
    "def get_mobilenet_ops(model, input_size):\n",
    "    # First operation before blocks is a convolution\n",
    "    op = Conv2D(input_size=input_size, kernel_shape=(3, 3, 3, 44), \n",
    "                strides=(2, 2), padding='same', \n",
    "                use_bias=False, activation='relu')\n",
    "    ops = [op]\n",
    "    input_size = get_conv_output_size(input_size, op.kernel_shape[0], 'same', op.strides[0])\n",
    "    \n",
    "    # Get all relevant operations from blocks\n",
    "    for child in model.modules():\n",
    "        # If child is of block type, get all operations inside the block\n",
    "        if isinstance(child, models.mobilenet.InvertedResidual):\n",
    "            for block_child in child.modules():\n",
    "                if isinstance(block_child, nn.Conv2d):\n",
    "                    op = build_mobilenet_conv_op(block_child, input_size)\n",
    "                    ops.append(op)\n",
    "                    input_size = get_conv_output_size(input_size, op.kernel_shape[0], op.padding, op.strides[0])\n",
    "            # Account for residual connection\n",
    "            if child.use_res_connect:\n",
    "                op = Add(input_size=input_size,\n",
    "                         n_channels=op.kernel_shape[3])\n",
    "                ops.append(op)\n",
    "    \n",
    "    # There is one last conv2D after all the blocks  \n",
    "    last_conv = Conv2D(input_size=input_size, kernel_shape=(1, 1, 448, 1792), \n",
    "                strides=(1, 1), padding='valid', \n",
    "                use_bias=False, activation='relu')\n",
    "    # After all of the blocks pooling layer and linear layer follows\n",
    "    pool_op = GlobalAvg(input_size=input_size,\n",
    "                       n_channels=1792)\n",
    "    dense_op = FullyConnected(kernel_shape=(1792, 1000),\n",
    "                       use_bias=True,\n",
    "                       activation=None)\n",
    "    ops.extend([last_conv, pool_op, dense_op])\n",
    "    return ops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ops_baseline = get_mobilenet_ops(model=baseline_model, input_size=start_image_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Counts for the baseline MobileNetV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ADD_BIT_BASE = 32\n",
    "MUL_BIT_BASE = 32\n",
    "BASELINE_PARAMETER_BITS = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_counts(total_params, total_mults, total_adds, mul_bits, add_bits):\n",
    "    # converting to Mbytes.\n",
    "    total_params = int(total_params) / 8. / 1e6\n",
    "    total_mults = total_mults * mul_bits / MUL_BIT_BASE / 1e6\n",
    "    total_adds = total_adds * add_bits / ADD_BIT_BASE  / 1e6\n",
    "    return total_params, total_mults, total_adds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_params_baseline, total_mults_baseline, total_adds_baseline = [0] * 3\n",
    "for op in model_ops_baseline:\n",
    "    param_count, flop_mults, flop_adds = count_ops(op=op, sparsity=0, param_bits=BASELINE_PARAMETER_BITS)\n",
    "    total_params_baseline += param_count\n",
    "    total_mults_baseline += flop_mults\n",
    "    total_adds_baseline += flop_adds\n",
    "\n",
    "total_params_baseline, total_mults_baseline, total_adds_baseline = process_counts(\n",
    "                                             total_params = total_params_baseline,\n",
    "                                             total_mults = total_mults_baseline,\n",
    "                                             total_adds = total_adds_baseline, \n",
    "                                             mul_bits = MUL_BIT_BASE,\n",
    "                                             add_bits = ADD_BIT_BASE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Counts for our pruned model of EfficientNetB2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First let's load the architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model = EfficientNet.from_name('efficientnet-b2')\n",
    "# print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get all the operations in the EfficientNet architecture - as stated earlier in the remark we can ignore BatchNorm layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_image_size = 260\n",
    "#kernel_shape = k_size, _, c_in, c_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mb_block_ops(mb_block, input_size):\n",
    "    ops = []\n",
    "    mask = []\n",
    "    m_name = '_expand_conv'\n",
    "    if hasattr(mb_block, m_name):\n",
    "        module = getattr(mb_block, m_name)\n",
    "        op = Conv2D(input_size=input_size,\n",
    "               kernel_shape=module.kernel_size + (module.in_channels, module.out_channels),\n",
    "               strides=module.stride,\n",
    "               padding='same',\n",
    "               use_bias=True,\n",
    "               activation='swish')\n",
    "        ops.append(op)\n",
    "        mask.append(1)\n",
    "        \n",
    "    m_name = '_depthwise_conv'\n",
    "    module = getattr(mb_block, m_name)\n",
    "    op = DepthWiseConv2D(input_size=input_size,\n",
    "            kernel_shape=module.kernel_size + (module.in_channels, 1),\n",
    "            strides=module.stride,\n",
    "            padding='same',\n",
    "            use_bias=True,\n",
    "            activation='swish')\n",
    "    ops.append(op)\n",
    "    mask.append(1)\n",
    "    input_size = get_conv_output_size(input_size, op.kernel_shape[0], 'same', op.strides[0])\n",
    "    \n",
    "    if mb_block.has_se:\n",
    "        se_reduce = getattr(mb_block, '_se_reduce')\n",
    "        se_expand = getattr(mb_block, '_se_expand')\n",
    "        op = GlobalAvg(input_size = input_size,\n",
    "                       n_channels=se_reduce.in_channels)\n",
    "        ops.append(op)\n",
    "        mask.append(0)\n",
    "        # input size is 1\n",
    "        op = Conv2D(input_size=1,\n",
    "               kernel_shape=se_reduce.kernel_size + (se_reduce.in_channels, se_reduce.out_channels),\n",
    "               strides=se_reduce.stride,\n",
    "               padding='same',\n",
    "               use_bias=True,\n",
    "               activation='swish')\n",
    "        ops.append(op)\n",
    "        mask.append(1)\n",
    "        op = Conv2D(input_size=1,\n",
    "               kernel_shape=se_expand.kernel_size + (se_expand.in_channels, se_expand.out_channels),\n",
    "               strides=se_expand.stride,\n",
    "               padding='same',\n",
    "               use_bias=True,\n",
    "               activation='sigmoid')\n",
    "        ops.append(op)\n",
    "        mask.append(1)\n",
    "        op = Scale(input_size = input_size,\n",
    "                   n_channels=se_reduce.in_channels)\n",
    "        ops.append(op)\n",
    "        mask.append(0)\n",
    "    \n",
    "    m_name = '_project_conv'\n",
    "    module = getattr(mb_block, m_name)\n",
    "    op = Conv2D(input_size=input_size,\n",
    "               kernel_shape=module.kernel_size + (module.in_channels, module.out_channels),\n",
    "               strides=module.stride,\n",
    "               padding='same',\n",
    "               use_bias=True,\n",
    "               activation=None)\n",
    "    ops.append(op)\n",
    "    mask.append(1)\n",
    "    \n",
    "    if mb_block.id_skip:\n",
    "        if type(mb_block._block_args.stride) is not list:\n",
    "            stride = [mb_block._block_args.stride]\n",
    "        else:\n",
    "            stride = mb_block._block_args.stride\n",
    "        if all(s == 1 for s in stride):\n",
    "            if mb_block._block_args.input_filters == mb_block._block_args.output_filters:\n",
    "                op = Add(input_size=input_size,\n",
    "                        n_channels=se_reduce.in_channels)\n",
    "                ops.append(op)\n",
    "                mask.append(0)\n",
    "    \n",
    "    return ops, input_size, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_efficientnet_ops(model, input_size):\n",
    "    ops = []\n",
    "    mask_for_sparsity = []\n",
    "    # First operation before blocks is a convolution\n",
    "    m_name = '_conv_stem'\n",
    "    module = getattr(model, m_name)\n",
    "    op = Conv2D(input_size=input_size,\n",
    "               kernel_shape=module.kernel_size + (module.in_channels, module.out_channels),\n",
    "               strides=module.stride,\n",
    "               padding='same',\n",
    "               use_bias=True,\n",
    "               activation='swish')\n",
    "    ops.append(op)\n",
    "    mask_for_sparsity.append(1)\n",
    "    input_size = get_conv_output_size(input_size, op.kernel_shape[0], 'same', op.strides[0])\n",
    "    \n",
    "    # Iterate over blocks\n",
    "    blocks = getattr(model, '_blocks')\n",
    "    for i in range(23):\n",
    "        mb_block = getattr(blocks, str(i))\n",
    "        block_ops, input_size, mask = get_mb_block_ops(mb_block, input_size)\n",
    "        ops.extend(block_ops)\n",
    "        mask_for_sparsity.extend(mask)\n",
    "    # Conv head\n",
    "    m_name = '_conv_head'\n",
    "    module = getattr(model, m_name)\n",
    "    conv_head = Conv2D(input_size=9,\n",
    "               kernel_shape=module.kernel_size + (module.in_channels, module.out_channels),\n",
    "               strides=module.stride,\n",
    "               padding='same',\n",
    "               use_bias=True,\n",
    "               activation='swish')\n",
    "    \n",
    "    # Average pooling\n",
    "    pool = GlobalAvg(input_size=9,\n",
    "                   n_channels=module.out_channels)\n",
    "    # Linear layer\n",
    "    linear = FullyConnected(kernel_shape=(module.out_channels, 1000),\n",
    "                           use_bias=True,\n",
    "                           activation=None)\n",
    "    ops.extend([conv_head, pool, linear])\n",
    "    mask_for_sparsity.extend([1,0,1])\n",
    "    return ops, mask_for_sparsity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ops, mask_for_sparsities = get_efficientnet_ops(model=model, input_size=start_image_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's calculate the sparsities for each layer. Our method prunes the architecture on per-layer basis, hence the sparsity levels across layers differ. We can calculate the sparsity for each layer using `weigth_mask` (bit mask for the model weight). The percentage of 0s is equivalent to the sparsity level of a given layer. (Note: the order of layers in the `weight_mask` is the same as the order of layers in the `model_ops` list)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"weightsmasks_effnetB2.bin\"\n",
    "weight_mask = torch.load(path, map_location='cpu')\n",
    "total_weights_per_layer = [l.numel() for l in weight_mask]\n",
    "zeros_per_layer = [torch.sum(l==0).item() for l in weight_mask]\n",
    "sparsity_per_layer = [zeros/total for (zeros, total) in zip(zeros_per_layer, total_weights_per_layer)]\n",
    "# Pad with zeros for non-convolutional and non-linear layers\n",
    "sparsity_per_layer_temp = sparsity_per_layer\n",
    "sparsity_per_layer = []\n",
    "index = 0\n",
    "for i in mask_for_sparsities:\n",
    "    if i == 0:\n",
    "        sparsity_per_layer.append(0)\n",
    "    else:\n",
    "        sparsity_per_layer.append(sparsity_per_layer_temp[index])\n",
    "        index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our pruned model we are using the 'freebie' 16-bit quantization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "PARAMETER_BITS = 16\n",
    "ADD_BITS = 32\n",
    "MULT_BITS = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_params, total_mults, total_adds = [0] * 3\n",
    "for op, sparsity in zip(model_ops, sparsity_per_layer):\n",
    "    param_count, flop_mults, flop_adds = count_ops(op, sparsity, PARAMETER_BITS)\n",
    "    total_params += param_count\n",
    "    total_mults += flop_mults\n",
    "    total_adds += flop_adds\n",
    "    \n",
    "total_params, total_mults, total_adds = process_counts(total_params = total_params,\n",
    "                                                           total_mults = total_mults,\n",
    "                                                           total_adds = total_adds, \n",
    "                                                           mul_bits = MULT_BITS,\n",
    "                                                           add_bits = ADD_BITS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameter storage score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our parameter score is: 0.3096718115942029.\n"
     ]
    }
   ],
   "source": [
    "# We overwrite our baseline number calculations due to discrepencies with counts provided by organizers\n",
    "total_params_baseline = 6.9 / 8 * 32 #(in MBytes)\n",
    "param_score = total_params/total_params_baseline\n",
    "print('Our parameter score is: {}.'.format(param_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Math operations score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our math operations score is: 0.518428176923077.\n"
     ]
    }
   ],
   "source": [
    "total_flops_baseline = total_adds_baseline + total_mults_baseline\n",
    "# We overwrite our baseline number calculations due to discrepencies with counts provided by organizers\n",
    "total_flops_baseline = 1170 #(in millions)\n",
    "total_flops = total_adds + total_mults\n",
    "flops_score = total_flops/total_flops_baseline\n",
    "print('Our math operations score is: {}.'.format(flops_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Total score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our total score is: 0.8280999885172798\n"
     ]
    }
   ],
   "source": [
    "total_score = param_score + flops_score\n",
    "print('Our total score is: {}'.format(total_score))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (pytorch)",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
